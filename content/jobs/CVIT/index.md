---
date: '5'
title: 'Research Assistant'
company: 'CVIT Lab'
location: 'Hyderabad, India'
range: 'January 2019 - Present'
url: 'https://skeleton.iiit.ac.in/'
---

- Our deep learning model MUGL enables large-scale(> 100 activities), diverse, and variable length generation of single and multi-person pose-based action sequences with locomotion.
- Overcame several shortcomings of MUGL by incorporating dedicated representations for finger joints and introducing a novel spatio-temporal transformation block with multi-head self attention.
- Studied current and upcoming frontiers of skeleton-based human action recognition. Also, introduced several datasets: Skeletics-152 (a large-scale action dataset), Skeleton-Mimetics (out-of-context actions) and Metaphorics (caption-style annotation of Dumb Charades and interpretative dance)
